2023-09-06

<https://surfingcomplexity.blog/2023/08/20/why-lfi-is-a-tough-sell/>

`RCA` ( root cause analysis )
`LFI` (Learning from incidents) <https://www.learningfromincidents.io/>

`miscalibration` to describe incorrect mental modesl,
and `structural secrecy` , a mechanism that leads to incorrect mental models.

<https://press.uchicago.edu/ucp/books/book/chicago/C/bo22781921.html>

" ... But incorrect mental models  are not something we talk much about
explicitly in the software world. The RCA approach implictily assumes there's
only a single thing that we didn't know: the root cause of the incident."

"... on the one hand, organizations recognize that experise leads to better
decision making: it's why they are willing to hire senior engineers even though
junior engieneers are cheaper.  On the other hand, hirign seems to be the only
context where this is explicitly recognized. This activity will advance the
expertise of our staff, and hece will lead to better future outcomes, so it's
worth investing in. That is the kind of mentailty required to justify LFI

"" \_\_\_
