# 2022-05-12

https://codecraft.co/2015/04/08/a-grumble-about-buckets/#more-6049

"
I'm grumbling about my choice of buckets, but in the end, its not the bucket menu, in and of itself that bugs m. I get why you m ight need to simplifyf, you can't please everyone.

What bugs me is that software with poorly chosen buckets also tends to be software that - either by intent or carelessness - provides no way whatsoever for its creators to find out if they've got the buckets wrong.
"


___

https://www.youtube.com/watch?v=70DAP_E-Xd0

to be a valid dfa we need a valiad transition from each node, with regards to an certain input. 

___




https://www.youtube.com/watch?v=oSpx2ROVfd0

stable matching 

people about to be medics apply to residency around hospitals .
hospitals compete for the best docs, trying to lock them in years in advance

the stable matching is responsible to satisfy the preferences of both medical and hospitals by receiving a ranked preference from both of them.


input size of ( 2N + 2N**2)
output should be 
    . should have the property: "No one should have gone and chose a different match outside of the mechanmism." 

A match is perfect if every doctor and every hospital appears exactly once. 
    . An instability is a pair of ( H , D ) that were not put together, but both would prefer having being paired with each other than the pair they have been given.


We can solve it with a "Deffered-Acceptance Algo"

"While existis a unmatched doctor D:
    
    H = top Hospital D hasn't applied to. 

    If H is unmatched: Match ( D , H )

    else, 
        if H prefers the current doctor over the current match,
            . Unmatch ( Dprev , H)
            . Match ( D , H)


___


https://www.youtube.com/watch?v=PT_qEhesKW8


ip addresses can be presented in octal format
- that can cause problems. 


___

https://www.youtube.com/watch?v=DmtSivtE3qY

heapsort

```python
function heap_sort( array ):

head = heapify( array )
for i in range(len(array)):
    array[i] = remove_min( heap )


def heapify( array ):
    heap = copy( array )
    for i in range( len( array )):
        idx = len( array) - i + 1
        bubble_down( heap , idx )
    return heap

def remove_min( heap ):
    m = heap[ 1 ]
    swap( heap , 1 , length )
    length = length - 1 
    bubble_down( heap , 1 )
    return m

def bubble_down( heap , i ):
    while 2 * i <= length :
        c = smallest_child( heap , i)
        if heap[ i ] > heap[ c ]:
            swap( heap , i , c )
            i = c
        else:
            break

def smallest_child( heap , i):
    l = 2 * i
    r = 2 * i + 1
    
    if l == length:
        return l
    elif heap[l ] < heap [ r ]:
        return l 
    else :
        return r

```

a heap is a complete binaryh tree with the heap property
    ( Every level is full , except the last , which is filled from the left.)
    . Because everything is full, we can store it as an array, where the position corresponding to the order of a level - by - level traversal
    . That means if we know where a value is, we can calculate where its children are.

*conceptual heap* , *actual heap*

a binary tree has the heap property if everynode has key no larger than its childrens


Big O Analysis:
Swap is O(1)
    Really, O( 3*C1 + C2 ) , Where C1 is index time, and C2 is call overhead.
Smallest_child is O( 1 )
    C2 is call overhead
    C1 + C3 , where C3 is arithmetic and C1 is assignment.    
    There is Also C4 for equality / branching / comparison . 
Bubble_down is O( Log( n ))
    the body is O( 1 ), but it does it many times. 
    Since each time it doubles, this is Log

Correctiveness
    * recursive writing can help easier the inductive proof of the algorithmn .
If tree H is an almost-a-help with the only violation of the heap property occurring at node i, then bubble-down( h , i ) makes h a heap. 


___

Laziness lets us separate the description of an expression from the evaluation of
that expression. This gives us a powerful ability — we may choose to describe a
"larger" expression than we need, then evaluate only a portion of it. As an
example, consider foldRight — we can implement this for much like Stream
we did for , but we can implement it lazily: List
def foldRight[B](z: => B)(f: (A, => B) => B): B =
 uncons match {
 case Some((h, t)) => f(h, t.foldRight(z)(f))
 case None => z
 }
This looks very similar to the foldRight we wrote for , but notice how List
our combining function, , is non-strict in its second parameter. If chooses not to f f
evaluate its second parameter, this terminates the traversal early. We can see this
by using foldRight to implement , which checks to see if any value in exists
the matches a given predicate. Stream
def exists(p: A => Boolean): Boolean =
 foldRight(false)((a, b) => p(a) || b)
Since foldRight can terminate the traversal early, we can reuse it to
implement rather than writing an explicit recursive function to handle exists
early termination. This is a simple example where separating the concerns of 
describing a computation from the concern of makes our descriptions evaluation
more reusable than when these concerns are intertwined. This kind of separation of
concerns is a central theme in functional programming.

___


EXERCISE 10: We can write a more general stream building function. It takes
an initial state, and a function for producing both the next state and the next value
in the generated stream. It is usually called : unfold
def unfold[A, S](z: S)(f: S => Option[(A, S)]): Stream[A]
Option is used to indicate when the should be terminated, if at all. The Stream
function is the most general -building function. Notice how unfold Stream
closely it mirrors the structure of the data type. Stream
unfold and the functions we can implement with it are examples of what is
sometimes called a function. While a recursive function consumes data corecursive
and eventually terminates, a corecursive function produces data and coterminates.
We say that such a function is , which just means that we can always productive
evaluate more of the result in a finite amount of time (for , we just need to unfold
run the function one more time to generate the next element). Corecursion is also f
sometimes called guarded recursion. 

chapter 5 is very good. 
chapter 6 is very good. 

___


In Part 1, very little design effort went into creating these nicely compositional
libraries. We created our data types and found, perhaps surprisingly, that it was
possible to define a large number of useful operations over these data types, just by
combining existing functions. When you create a library for a new domain, the
design process won't always be this easy. You will need to choose data types and
functions that facilitate this compositional structure, and this is what makes
functional design both challenging and interesting



