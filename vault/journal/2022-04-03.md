# 2022-04-03



Port forward

Can be done in the router.
    . Ugly, 

iptables
     

    

nat



transparent proxying


why don't we just run the app in port 80?
    . ports 0 to 1024, these are system ports, 
    . cant listen on then unless root
        -> Security concerns. 

insert rows in the nat table. 
    . "please forward to me , on this other port"
    . uses iptables -> System call , need sudo 
        -> sudo iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination 192.168.254.47:8080

    |> needs to be a ip, cant be dns
when routing to another machine, we need to use maskarade 
    . sudo iptables -t nat -A postrouting -p tcp --dport 80 -j MASQUERADE --to-destination ....

these are session only. to persist,  need to use apt-get install iptables-persistent

clearing
    sudo iptables -t nat -F
    
# 


your router is the one who has the public ip address
    . How does it knows to forward the requests?

    . There are many, for example
        .. Port Forwarding
    
Port Forward is a table configured inside the router, which allows it to forward the requests
    . However, your ip must be static , because the ip in the table is static. 


# 

Network Address Translation
    
    Maps a ip address to another ip address
        ( or a ip_address:port pair to another one )
    
    Originally designed to solve the only 4bi ipv4 devices

    not only application
        . 

    

    devices inside the same network can communicate directly by finding each other mac addresses using arp


check if its in the same subnet, does an arp request 
else, it calls its default gateway
    when rounting a request, the router will:
        check if its an unroutable ip addresses.

if 
router vs switches?


can use to do more things
    . Instead of having root access to listen on port 80.

    . load balancing: takes the packets coming, and create a virtual ip addresses ( VIP ). the vip gets an entry in the nat table  
        
DNS 
    . Can point to ip:ports via SRV records


# 
ARP

Maps Ip addreses to mac addresses 

Why?
        
        we need mac to send frames ( layer 2 )

        Most of the time, we know the ip address , but not the mac. 
        
        this process is expensive, so its cached locally, in an ARP table 

Network Frames
    
    encapsules the ip packet

    ![](2022-04-03-12-13-24.png)
    
    what if the target ip address does not fall inside the local network?

    in this case , the application sends an arp request looking for a default gateway. then, it builds the network frame and sends it. 


# 

Osi model 
 
open system interconnections


layer 7 applicatoin
layer 6 presentatoin -> Encrypt if necessary
layer 5 Session -> Establish session ; tag it. 
Layer 4 Transport -> Add ports/seq ; Break into segments;
Layer 3 Network -> Adds IP ; Now, called a packet. 
Layer 2 Data Link -> Breaks packets and adds the Target Mac ADdresses  ; Now Called Frames, have basic error detection 
Layer 1 Physical -> Tranforms into 1 and 0, into electric / optical / radio waves

frames are fixed size 
frames are received by everyone in the same broadcast domain, but the network card just discards it ( unless its a broadcast or multicase addressed) . It can be configured to not do so, and forward every packet: This is called promiscuous mode. 

where does the tcp buffer enter her?? [[expand]]


# 

TCP Tunneling is the proccess of encapsulating content from a protocol A to a protocol B , usually because A is unnavailably. 
    
    .. Isn't this just IPSEC?
    .. Or proxying 

Applications

    Local port forwarding tunnel
    Reverse Port Forwarding tunnel
    SOCKS proxy ( dynamic port )

This can cause TCP meltdown ( tcp over tcp )
    tcp isn't a lightweight protocol 
        congestion control, retransmission, garantee delivered, checksumming, 
    doing a tcd inside a tcp inside a tcp ... can slowdown everything


# 

For some time now i have this conception of what a "learning" workflow would ideally look like  

Earlier on, i was trying to use other "specialized" apps , such as roam and obsidian, but i kept hitting this barrier of operational friction ; 
Had to remap a lot of things, workaround lack of support ; I went to the length of coding an entire plugin to be able to do my shortcuts
(https://github.com/tgrosinger/leader-hotkeys-obsidian/pull/19), which was merged yesterday btw.

In summary, this operational friction isn't good, and from my findings, there wouldn't be that much great gains anyway. Any that might exists can be acessed by using the app in a read-only way, while letting the editor do the write-edit heavy part.

With this out of the way, i could focus better on the note-taking content, per se

___ 

In regards to note-taking, the approach i've settled down on was a incremental one: Every day i create a single new note , with the date. In this note i just write down streams of thought, with very little structure. 
When i "feel like it", i just go over these previous day streams, and pick them apart for the good bits. The connections and structured content comes about in only a second moment : this is something that i would consider key. 

For the results, i feel like taking a more structured ( but still organic ) approach to learning makes me more mindful of the process. 
Being able to spot those 'gems' that come into our minds, which we know are good content but would not otherwise solidify. 
The connection-part thing is very interesting also - Seems like i'm always on the lookout for parallels and analogies now , which i consider a good thing. 


All in all , its been pretty good, would def recommend. 

The key points should be like:
    1 . Overcome the operational friction by incorporating it inside my editors
    2 . Having triggers for doing it
    3 . Don't stressing about immediately producing structured content.

As an exemplification of the above concepts:
    1 .  I'm using foam / dendron inside vscode , so writing and editing feels way easier
    2 . I developed a web page that gets brought whenever i hit a new tab - This page picks 5 random articles from my readlist and displays them to me. 
    3 . Having the daily stream of thought file. 


Some great things about having a "simple"  workflow is that:
    .  Easily versionable. This gives me a lot of security , knowing that its always backed up somewhere and i can just undo whatever / whenever.
    . Its flexible: I incorporated my read lists into it ( the lists inside the /other folder. ), and since its text, i can interact with it via custom scripts easily. Currently, i'm able to write down basically every page i visit using autohotkeys, and mark it down as read using python. Also using scripts to create the web page.

For a time now, i've been thinking about what would an ideal learning workflow be:
    . I  would have a structured "Knowledge Sources", such as rss feeds and other read lists
    . I would have some kind of way to process and archive the golden nuggets 
    . I would have some kind of way to go over these archives, re-learning them. A big issue i had recently was just forgetting things. Feels like for every two things i learn i forgot about another one. 

Up until now i was able to structure only the first one. I feel like zettelkasten has been a good way of implementing the second one. I plan to implement some kind of active-recall or spaced-repetition routines to re-learn what i wrote down. 
And i kinda get excited about other possibilites - Can i integrate this with technologies such as GPT3, as to have a *very* personal assistant? 


# 



Similarly one may ask, what is loopback used for?

1 Answer. The loopback device is a special, virtual network interface that your computer uses to communicate with itself. It is used mainly for diagnostics and troubleshooting, and to connect to servers running on the local machine.

is not sent through a real network interface , even if sent to an address on one of the machine network adapters;


windows does not implement a network loopback interface ;



SSDP is a zero-configuration networking protocol designed to allow nodes to be added and removed from a network without any involvement from a central service such as DNS or by assigning static IP addresses to specific nodes. This decentralised, dynamic approach is possible because SSDP uses UDP as it's underlying transportation protocol which allows for multicast communication.


PSH Flag in TCP
The Push flag usually means that data has been sent whilst overriding an in-built TCP efficiency delay, such as Nagle’s Algorithm or Delayed Acknowledgements.

These delays make TCP networking more efficient at the cost of some latency (usually around a few tens of milliseconds). A latency-sensitive application does not want to wait around for TCP’s efficiency delays so the application will usually disable them, causing data to be sent as quickly as possible with a Push flag set.


tcp buffers?

# 

go over the firewall rules and understand them.

AllJoynRouter?
App Installer?
CAptive Portal Flow
Cloud Identity? 

Cortana
Desktop App Web Viewwer
Connected User Experiences and telemetry
Email and accounts
Get Help
iSCSI service
Mail And Calendar
mDNS
Microsoft Content
Microsoft Edge
Microsoft family features
Microsoft Pay
Microsofdt Photos
Microsoft Dticky Notes
Narrator
NcsiUwpApp
Network Disovery



LLMNE-UDP-OUT?
NB-Datagram-out?
nb-name-out?
pub-wsd-out?
ssdp-out
upnphost
upnp
wsd events
wsd eventsSecure
wsd out
paint 3d
proximity sharing
remote-assistance ( PNRP)
remote-assistance ( ra )
remote-assistance (ssdp)
start
store experience host
take a test
wifi direct network discovery
wifi direct scan service
wifi direct spooler use
windows calculator
windows camera
windows default lock screen
windows defender smartScreen
windows device management
windows feature experience pack
windows search
windows security
windows shell experience
wireless display
wfd asp coordination protcol
wfd driver only
work or school account
xbox game ui
your account

;



ICMP and IGMP are both used for multicast management
IGMP for ipv4, and ICMP for ipv6



IGMP Messages:

General Memeberip queries
Group specific queries
groupo and source specific queires
membership reports
    
leave group messages

This was sent to 224.0.0.252. Why?
    . 224.0.0.22, and 224.0.0.241 are in my arp table.
    d. 239.244.255.250 is also. 
    . 224.0.0.22 does not go away when flushing my arp tables.
    . It is also the one i semd my first IGMPv3 too. 
    what is an inet_address?
# 

In DHCP, i was the one requesting the address. Why? Is this always the case? How do i know that i correctly received that ip address?
    Where is the parameter request response?
        . Now that i flushed my caches, the responses came in a following ack request. 
            .. Later i'll try again without flushing. 
    Is the destination always 255.255.255.255?
    It seems that the client is the one that initiates a ip proposal. Is it the case? Can the server reject it?
    
    It seems that dhcpv6 does things similarly. However, it sends to ff02::1:2
    
    It seems that following the dhcp request, our pc asks over the broadcast "Who is 192.168.1.1 - the router / domain name server / dhcp server"
    
After this is complete, it seems we start to contact via IGMP and ICMP. 
    . It sends IGMP to 224.0.0.22 , which is the entry that wasn't flushed with arp -d. 
        .. It starts with a report / join group for any sources ( 224.0.0.252 and 224.0.0.251)
    then a leave group 
    . It also Sends ICMP to ff02::16

    In ICMP, the first request was sent to ff02::16 - A multicast listener report message. Why?
        . Now that i flushed my caches, it seems that a message is sent before: A Neighbor soliciation for fe80:9a7e. This is leaving my pc with destination ff02::1:ff3b:b7d0. 
            .. Why? How we know the destination?

    The wikipedia article seems to imply that these protocols do not operate atop a transport layer. Why and how?

After these are done we do dhcpv6 , and NBNS as well as mdns and llmnr
    .. 224.0.0.251 seems to handle mdns, while 252 handles llmnr, with 22 handling igmp

then, its connecting to microsoft stuff

among these mdns, why are we asking for ourselves?

    many many times, actually. 

# 

how do i display my dns cache?
    ipconfig /displaydns.

What is LLMNR?


msftconnecttest.com ( A, AAAA )
skydrive.wns.windows.com ( A , AAAA )
lincensing.mp.microsoft.com


what is a arp probe?



port 3702 ws-discovery
tcp wsapi


i *really* don't like what i see. 

Name Resolution

# 

source 0.0.0.0 to 255.255.255.255 ( dhcp discover )

source desktop-05AI9DR.local to ff02::16 
	ICMP v6 ( Multicast LIstener Report Message )
	ICMP v6 ( Neighbor SOlicitation )
	ICMP v6 ( Neighbor Advertisement )

source desktop-05AI9DR.local to ff02::16 
	IGMP v2 ( Membership Report group )



source desktop-05AI9DR.local to ff02::1:3
	LLMNR Standard query ANY DESKTOP-05ai



source desktop.local fe80 for DNS => Very quick we get a response


several ARP


Several QUIC to google.
	SEVERAL.
	WHY


DHCP v6 to ff02::1:2 => UDP port 547
	Solicit, folowwed by advertise. 
		IA address given, alogside DNS recursive name server
			fe80 9a7e

	What is DUID??

	who gives me an ipv6 address??


chatting with wns.notify.trafficmanager
	. Where did it get its ip from?

lookups for some domains
	msftconnecttest
	skydrive
	

tcp handshake and http chat with  4-c-0003.c-msedge.net

More membership reports via igmp
more multicasts via icmpv6


who is investus_3b:b7:d0

why am i asking so much for 192.168.15.2?



wireshark only use the profile "hosts" file?
resolve vlan ids?
resolve ss7 pcs?
enable oid resolution?
suppress smi errors?
maxmind database?


wireshark statistics
big ip system?



# 


Dirichlet distribution 


A distribution over probability distributions
    kinda like a generalized multinomial distribution?

prior distribution over pmfs

# 


Kernel Methods

a class of algorithms for pattern analysis. 
    . Find and study general types of relations 
    . usually, the raw data is explicitly transformed into a feature vector via a user-specified feature map. Kernel methods require only a user-specified kernel, that is, a similarity function over pair of data points in raw representation. 

Kernel functions operate in a high-dimensional , implicit feature space without ever computing that space, but rather, the inner products between the images of all pairs of data in the feature space. This is called the Kernel Trick. 
    . Gaussian Proccesses
    . PCA
    . Spectral Clustering
    . Linear Adaptive Filters
    . Kriging
    . Inverse distance weighting
    Usually based on convex optimizatoin and eigenproblems, are statiscially well founded
        . rademacher complexity?
        . Mercer's condition?  > associates a inner product to any positive definite matrix? 
        . counting measure?

            
"Rather than learning some fixed set of parameters corresponding to the features of their inputs, they instead "remwember" the ith training example and learn for it a corresponding weight. predicition, them is treated by the application of a similarity function ( kernel ) between the unlabeled input and each of the trainin inputs
    . Isn't this what K-neighbors does??

Gram Matrix ( sometimes called a kernel matrix ) must be apositive semi-definite ; 
    . If the kernel function is also a covariance function as used in gaussian processes, the gram matrix can also be called a covariance matrix. 
    Examples
        Fisher Kernels
        Graph Kernels
        Kernel smoother
        polynomial kernel
        raidal basis function kernel
        string kernels
        neural tangent kernel
        neural network gaussian process kernel


Usually, inner products produce a scalar output. What if we make it return a vector ionput?
    . Kernel methods for vector output. 
    . Can them compose then. 
    Examples
        co-krigin . 
    "Multi-label classification can be interpreted as mapping inputs to binary coding vectors with length equal to the number of classes."
    In gaussian processes ,multiple output functions correspond to considering multiple processes
    
    * Reproducing kernelk hilbert space?? 
    * . ATikhonov regularization?

    . Representer theorem?
        minimizer {\displaystyle f^{*}}f^{*} of a regularized empirical risk functional defined over a reproducing kernel Hilbert space can be represented as a finite linear combination of kernel products evaluated on the input points in the training set data.
        ??


Cover's theorem is a statement in computational learning theory and is one of the primary theoretical motivations for the use of non-linear kernel methods in machine learning applications. The theorem states that given a set of training data that is not linearly separable, one can with high probability transform it into a training set that is linearly separable by projecting it into a higher-dimensional space via some non-linear transformation. The theorem is named after the information theorist Thomas M. Cover who stated it in 1965. Roughly, the theorem may be stated as:

A complex pattern-classification problem, cast in a high-dimensional space nonlinearly, is more likely to be linearly separable than in a low-dimensional space, provided that the space is not densely populated.

; 

Big data 
https://www.youtube.com/watch?v=VYLWyS8UNm8


Logging and metrics tools


    . Difficult to feel the system 
    Best Practices
        Operations room 
        dashboards - aggregate information highlighting
    
                                                Metrics / Monitorings : Dashboards alers
    systems > log aggregation & analytics engine =<
                                                Incident response: log serrch, drilldown 

dimensions in tool space
    Logs vs Metrics
        . Logs are events - metrics are aggregates
        . Logs have high dimensionality - metrics have low dimensionality
        . Logs tend to be unstructured - Metrics are structured
        . Logs support drill-down analysis - Metrics Leans towards dashboards and alerts
        . Logs will vary in volume - metrics have a fixed volume rate
        . Logs tend to be high volume - metrics tend to be low volme 

    Historic vs real-time
        . Historic is good for incident response and audits ; real time are good for alerts and dashboards
        . Historic allows to uncover unknown issues; real-time are for known issues ;
        . historic requires disk ; real-time requires cpu 
        
    cloud vs on-prem
        cloud may bhave privacyu and security concerns
        cloud can pay as you go - on prem requires dedicated hardware ( operational vs capital expenses )
        cloud doesn't need to manage. .. .
    
    schema vs ad-hoc
        schema-based systems addresses knwon issues to look ou for ; adhoc enables to dig into new unkown issues
        schema <> index, but they often go hand in hand
            . trade offs between effort on write or effort on read. 
    

Log analytics sweet spot
    record everything
    generate metrics from the logs in real time
    interactive / ad-hoc search on historic data
    _can_ be installed on-premises
    affordable

product team practtices
    
    Monitors with graphs 
        . Gives a sense of normality
        
    Be the customer 
        => DogFooding

    Safe Environment
        TAkes all kinds of peoples
        . "I'm not a good finisher"

    Be in doubt
        . Discuss trade offs - not do's and don'ts
        . Leave time to wonder
        . No one knows "what's best"
    High BUS factor
        . We depend on people ;
        . Don't try to make them replaceable
        . Everyone is responsible
    
    Take small steps
        . Running a saas with frequent deployments teaches you to take small steps
        . define design goals and dicuss tradeoffs. 
        . avoid long-running side-projects . feature-flag new work. 
    Manage critical dependencies
        . Own all critical components
        . tempting to pull in 200+ apache libraries
    
    Don't waste hardware
        . The most amazing achievement of the computer software industry is its continuin cancellation of the steady and staggering gains made by the computer hardware industry
            


careful engineering - data processing engine
    
    Events pass through either two paths 

    State Machine 
        .  "The query gets compiled into a state machine that is then fed the events"


    Event Store 

Aggregates

| Function | State | Step | Merge | Result  | 
count | n | n + 1 | n1 + n2 | n 
sum | ( n , s) | ( n+1 , s + value ) | ( n1 + n2 , s1 + s2) | s/n
stddev ( n , s , q ) | ( n  + 1 , s + value , q + value^2 ) | ( n1 + n2 , s1 + s2 , q1 + q2) | ( sqrt( n*q - s^2 ) / n ) 

> ring buffers


Event store : Fast filters
    . "Build minimal index and compress data"
        .. Can hold it in memory
    
Fast grep for filtering events
    

Start-time, end-time, metadata 
    
