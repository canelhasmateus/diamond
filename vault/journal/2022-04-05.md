# 2022-04-05



HIve
    
    Query Interface to hadoop ( HDFS)
        . Query ENgine
        . Metastore


    With time, other technologies dismantled there

    HDFS -> Object Storage ( AWS S3)
    Map Reduce -> Spark 
    Yarn -> Kubernetes
    Query Engine -> Presto / Trino


When saving new data, we register it into hive metastore
    . Maps a set of objects in the objsect store to a table exposed by hive
        .. Schema of the table held in the file, with metadata
    . Leads to 
        .. Virtualization
        When using sql, not interested in the detail of object stora. 

        .. Discoverability
        Becomes a catalog of all the collections held in object storage 
        Can also add supplemental: Update frequency, owners
        .. Schema Evolution
        Mutability is a challenge of managing data sets ; 
            Records may change over time with respect to the existing columns describing their attributes 
            The set attributes itself changes, resulting in a change to the schema
        


        .. Performance
            . Parition prunning? 

POssible replacements
    . Difficult to install and maintain
    . Not architected cloud-native, complicating managed service implementations
    . Scalability 5restrictions from relational db relianceow
    . No direct, but  . .. | specially because the metastore is a general interface supported by all applications. 
    

Open Table Formats
    . Iceberg
        efficiency in large tables
    . Hudi
        mutability
    . delta lkae
        mutability
        schema enforcement and evolution
    
Data Catalogs
    Many open source discovery tools
        acryl
        data portal
        amundsen
        apache atlas
        atlan
        azure purview
        castordoc
        collibra
        data galaxy
        data world
        databricks unity catalog
        datahub
        facebook nemo
        google data catalog
        metaphor
        netflix metacat
        secode
        select start
        shopify artifact
        spotryify lexicon
        stemma
        uber databook
        zeenea
Observability
    monitoring the quality of the data pipelines oeprationally, or the data itself
        . Databand 
        
        . great expectations
        . monte carlo ( https://www.montecarlodata.com/ )


# 

Durability is the guarantee that data can be accesses after a failure. It is not a vinary property, but should be defined as the "kinds" of failures you want your data to survive. 
    . Usually, there is some performance penalty for durability;
    . Rarely testing - involves cutting power, which is distruptiver and hard to automate. 


nvme
    writes of a single logicval block *must* be atomic. 
    block? sector? journal? raid | write cache?s

    . Commands rare submitted to devices using a set of queues. 
    At some tmie, the device acknowledges that the command have complete. There is no ordering guaranteed between commands. 
        . Host or application is required to enfornce that ordering.
            -> Software needs to wait for commands to complete before issuing the next commands. 
        . Guaranteed to return the most ocmpleted write, although they may also return data from uncompleted writes that have been queued. 

    In the case of concurrent writes to overlapping ranges, what are the permitted results? 
        . Not specified ;  weak ordering, sematics similar to memory in multithreading. 


# 

https://degoes.net/articles/newtypes-suck
https://degoes.net/articles/principled-typeclasses

Type classes ; object oriented interfaces ; ml-style modules
    . How do we abstract over a set of functions and types that might have multiple concrete implementations?

    intance = concrete implementation for a type class. 

    haskell can derive which implementation we're using automatically. 
    Scala: Implicits. 

    good and all 


Unprrincipled type classes
    Most type classes are ad hoc rather than pricipled - cant enforce laws. 
        . not ernforced by the compiler. 
        Example of unenforced laws: 
            Ordered
                . Transitive ( a <= b ; b <= c  |> a <= c)
                . Anti-symmetric ( a <= b ; b<= a |> a = b)
                . total  ( either a <= b or b <= a)


there are usually many possible ways to write an instance for a type that satisfies its laws
    
    . Integer  
        . Additive Monoid ( + )
        . Mulitiplicative Monoid ( * )

If there are multiple instances for a given type, with completely different behavior, which one the compiler choose?
    . Possibility of orphan instances, that is - the instance depends on what you import. 

    . People can work around by creating newtypes , but these are adhoc, and can be seem as a type of abuse, since they define no more requirements than the underlying implementation. 
        .. Programming by name
        .. Better to use smart constructors
        
Depedent-types 
    . can force verification of behaviour. 
    . Not all, can't verify effects ( such as IO )


Newtypes are isomorphic to the single value they hold. 
    . "Programming by name" 
    .. Can still go wrong
    .. Worksaround  : Smart Constructors
        -> Paatch around the fact that our data model is underconstrained. 
    


Precision may be tedious due to limitations of the language we work in
    . Even more tedious is debugging broken code.

# 
https://www.anishathalye.com/2015/03/07/designing-a-better-judging-system/


Most judging methods are themselves flawed
    . There are constraints in the numbers of judges, and the amount of time there is for judging to take place; Given the constraints, how we produce the highest quality judging results possible?
        .. Isn't this what i'm doing with my read laters?
    
    . Instead of juding producing absolute scores, perform pairwise copmarisons. 
     
. Average 
    Judge A gives X a 7/ 10 ; Judge B gives a 4/10. What does that mean? is x objectively better than y? or is judge b harsher than a?
. Normalizing
    Improvement over average by normalizing judges scores ( by mean and std ).
        . Judges look at a tiny fraction of the entries. 

assigning numerical scores to entries is not a task that people are good at.
    . Judging the first entry, judges have no context and nothing to compare it to when assigning a score. After many entries, judges outlook may change - results aren't independent of the order they're judged. 

Pairwise comparison, on the otherhand, is something we're good at. 
    . We won't necessarily have a copmarison data between every pair of entries . We just do not want disjoint sets of entries that are never even indirectly compare to each other. 

    . Luce's choice axiom ???

    . How to turn the measurements into judging reults?


"Any pair of entries may be compared with each other zero or more times, and jusges may have conflicting opinions about the comparative quality of entries. " 
    . We can think of the measuresments as a directed graph on nodes , having non-negative integer edge weights derived from the number of times End was judged better than Ej -> Arrows point to better entries. 

    . Can also think of representation of the data that follows from the graph representation. 

    . Them, it is natural to thing about finding a topological sort of the comparisonn graph.
        .. However, The graph can be cyclic, so a topological sort might not even exist. 
        .. ANother approach is to define a permutation of the nodes ; define backward edges as a cuntion of th permutation, and define the cost of a given permutation as the sum of the weights of the backward edges, take the best permutation . Informally it represents finding  a ranking that the least number of judging decisions disagree with.  ( ?? didn't *really * what those mean)
    
    another choice is to loog elsewhere ( Phychology research ) to find good models for reasonng about paired comparison data .  > Probabilistic choice models > thurstone statitical model of judgements ; 
        . allows to  derive interval scale measurements from which we can extract rankings
        . Assumes that th equality of every choice is a gaussian random variable , and when a person judges the relative quality of two options, they sample from each of the corresponding quality and choose the one with higher measured quality. 
        . The true qiality is the corresponding gaussian; If we can figure out the means of the gaussians, we will have relative scores for every option, so we'l be able to determine a global ranking; 

        . If X ~ Nx and Y ~ Ny , then
            .. X - y ~ Nxy with uxy = ux - uy ; sxy = sx + sy
        . How to determine the best parameters for the model, then?
            . ~~~~

            "We can simplify our model such that ..  we have sxy = 1. " Isn't this an example of reverse pinning?
    
    http://people.stern.nyu.edu/xchen3/images/crowd_pairwise.pdf
        . "Instead of dispatching judges randomly, it assigns judges in such a way that maxizes expected information gain ; also updates rankinns efficiently in an online manner, taking o(1) to process single votes and O(n) to tell a judge where to go next 
        https://www.anishathalye.com/2015/11/09/implementing-a-scalable-judging-system/"




# 

 For 12 years I unquestioningly assumed the virtue — and importance — of intellectual honesty. Coincidentally, I also spent most of those years working alone.

Now that I've worked in teams for a while I'm starting to change my mind. In many social situations being apologetic sucks. It makes others around you feel awkward. If you're leading a team it makes you seem weak. If you're the rookie you sound like you're making excuses. If others aren't intimately familiar with the details it can magnify your screwups and make things seem worse than they are. 

http://akkartik.name/post/2010-12-18-07-52-06-soc

#

if you'reinterested in how chrome sees priority you can right click in the network panels table and add the priority column .



Priorization is a big deal. As ur apps gets bigger and more complex we need mechanisms to handle that. 

Avoid Locking the main thread - this is something that csr does;
SSR however, creates an uncanny valley of pixels that aren't really interactive 
progressive boot would be the best approach, but its not the easiest to use inside frameworks 


        


 # 


https://www.youtube.com/watch?v=6dDtN1wk5Qc

gRPC is a protocol built on top of http2 to support bmultiplexing, to  become language neutral
    . If i wanna communicate in a certain protocol, you need to understand that protocol, such as http, http2, postgres protocol


why not use one connection , instead of the connection pool in the database?
    head of line blocking
    how to know what packet is for who?
# 


Question Categories

    . Unknown => Why is chocolate so awesome
    .  Known => What is the popluation of bangladesh
    . Discoverable => How can i sell more widgets to housewives between the ages of 25 and 40. 


"The Central value proposition of big data is inseparably connected to *discoverable* answers. These gems are fundamentally different from facts waiting to be sliced, they're rational guesses based on deduction and supported by rigorous data analysis
    . Thats wyhy its called data science
    . If we're not building big data solutions that hypothesize rather than report, we're underdelivering. 



"Enterprise search struggles, as an industry because its trrying to sell drill bits to customers who want holes, and it's forgotten that it's the hole, not the bit, that makes the customer passionate"
    . I feel like this is deep and i'm not understanding it still. 

#

check https://haxe.org/
