# 2022-03-31



# 
TLS  passthrough at Layer 4 Proxy

L4 Proxying:
    The ability for the proxy to only look at L4 content:
        . Ip Address
        . Port

    When  doing that, not allowed to look at the content. Specially because most of the time, the L7 content, such as body and headers are going to be encrypted.

Suppose you're a client, and there is a server. 
You conncet to the server through a Reverse Proxy. 
~> You do a SYN . What happens then?
    Does the RP iotself replies and at the background it stablishes a tcp between itself and the backend?
    Does it merely forwards the request?
    
    There are pros and cons for each approach.

After stablishing tcp connectiion, we need to stablish a tls connection. Who is gonna respond to your tls request?
As a reverse proxy, we can either
    . Respond to the client with your own certificate and tls parameters ( TLS Termination , need to put the private key and certificate in the reverse proxy, but you do not always own it. )
        .. This gives the RP the ability to crack the encryption and 
        .. technically not termination 
    . TSL Passthrough is when , through the (SNI? eSNI?) , the Reverse Proxy just forwards the tls request, but can't decrypt the  content; This makes it operate just like L4 proxy. 

https://www.youtube.com/watch?v=iLHhL-vAPqo



# 
Proxies

A proxy is a software that makes a request on behalf of a client. 


Use cases:

    Block Websites
        Some enterprises and ISP use proxies to block unwanted  websites. 
    
    Caching
    
    Anonymity: The final destination does not known the originating client ( Just transfers anonimity, since the proxy is now the only who  knows ). 

    Logging: 
        Can log everybody requests, 

    Microservices
        Especially side car proxies. Make it take care of networking stuff, such as upgrading http protocols, circuit breaking, 

Take your requests, passes it. 
Thus, the proxy needs to look at the data. 





Reverse Proxies
    
    The reverse of a proxy: In a normal proxy, the server does not know the client. In a reverse proxy, the client does not known the final destination server. 

    
    Use Cases

        Caching

        Load Balancing
            

        Ingress:
            Hey, you talk to me sir,  and if you wanna access the pictures api, it can route requests. 

        Canary
            Try out new versions by sending small amounts of traffic to them. 

        Microservices
            
    

    HAProxy
    Envoy
    Ngins
    Istio
    Linkerd
    Caddy

Your final destination as a user, but you do no tknow which server  you're hitting. 

Can a proxy and a reverse proxy be used at the same time?
    . yes, this is called a service mesh
    . Used in microservices architectures to build the networking features of the application in the proxy, instead of making the application worrry about 
    timeouts and circuits breaking

Can i use a proxy instead of bpn for annonimity?
    . Yes, but usually vpns are more secure since they operate at a lower level, and can see only your domain
    . Some proxies can see not only the domain, if they're  TLS-terminating . 
        .. Go to the padlock and see that the content is being served by the final destination, not the proxy. 
    . VPNS just transfer your anonimity from the isp to the vpn. 


Can i use proxxy for traffic other than http?
    yes,. there are multiple types of proxy, like socks proxy, used for tunnelings, there are http proxy, that only tunnels for https;.

https://www.youtube.com/watch?v=SqqrOspasag
#





https://www.youtube.com/watch?v=SqqrOspasag&list=PLQnljOFTspQVMeBmWI2AhxULWEeo7AaMC


# L4 vs L7 reverse proxies
    

L4 ( TCP / Stream ): Packet or Stream Proxying 
L7 ( HTTP ): Application Layer Proxying 

For a L7 proxy, it needs to understand the request, 
    Each re3quest has its own connection
    which means that it can only proxy the request after acking all underlying packets. The same goes for the request. 

    Further requests in the same connection can potentially stablish new connections, with different servers, since http is a stateless protocol. 

For a L4 Proxy
    it doesn't need to wait for the assembly 
    of the whole request: Since it doesn't need to know details, it can immediatelly send the packets to the downstream server.

    Additionally, further requests re-utilize the same previous stablished tcp connection: TCP is NOT a stateless protocol. 


We can't do intelligent things while proxying blindly. 

Can we do a time diagram of these? [[expand]]



How about TLS?
    
    A Layer 4 proxy will look at tls requests  and just transparently pass it .
        . Only one implementation. We can also terminate TLS 
    

https://www.youtube.com/watch?v=ylkAc9wmKhc

#


    

TCP Handshake 
    


Every packet sent has to be followed by a acknowledgement. 
Each packet has a unique identifier, called a sequence number.  They're also used to handle out of order packets. 
How do we know which is the first sequence number, though? THese need to be coordinated, which happens through the tcp handshake. 
    . We don't start from the same sequence every time to prevent attacks such as replay attacks and syn attacks. 
    . Less hints are better. 

The first step happens at the client. It sends a SYN request to the server, containing its own sequence number. 
The server then responds with a requests: An SYNACK  containing a syn of its own sequence number, and a ack of the client sequence number. 
To finish, the client sends an ACK containing the server sequence number. 

Each ACK contains one value: The ack of the packet seuqence number summed with the packet length. 






https://www.youtube.com/watch?v=bW_BILl7n0Y

#


TLS Handhake

Agree To a key. 
    We need the cient and the server to use the same number. 
    
    We can't just generate one and send it over, otherwise some party in the middle could sniff it. 


    Diffie Helman 
        Key Exchange Algorithmn 
            Enables to exhange keys without middle parts knwing 

The client comes up with a private number X, and a public number G. 

The client will send the "Client Hello". It contains 
G and G^X , alongside its supported encryptions, and some tsl extensions ( ALNP ) , such as http 2, stapling , sni, encrypted sni. 

The  server then creates a number, Y, and replies with G^Y, alogside the agreed encryption scheme. 

Then , both server and client use ( G^x ) ^ y = ( G ^ y) ^ x = G^( x * y  ) as a secret number. 


there is something to do with another variable used to take the modulo that makes it impossible to derive x back from G and G ^ x. [[expand]]
Public-Key Encryption schemes can be MITM , but we solve this here by the use of certificates [[expand]]
 

https://www.youtube.com/watch?v=IE0QLCcOr0I
https://www.youtube.com/watch?v=rKVCTVAHK7k


# 

VPNS
https://www.youtube.com/watch?v=JIA4ca0afnY


Normally, whern connecting to a site, we first do a dns lookup to find the IP address of the domain.
With the IP address, it stablishes a tcp connection, binded to a specific port in the client and another and the server. 

When sending a request, we translate it into packets, and shove it inside a IP packet. 
An IP Packet has just a source and destination ip. 
IP isn't secure. Anyone in the route to yyour destination, such as your ISP, can know where you're going to. 
We can secure IP ( IPSec ) : A negotiation protocol between hosts. Once they exchange keys, they encrypt the whole IP packet, which means that every other protocol that goes above it gets encrypted for free. 
To get around addressability, we put this encrypted packet inside another ip packet, addressed to the host ( VPN )

IPSec is easily identifiable. 
    does this means isp's could block vpns? [[expand
    ]]


why we can't use mac addresses? because mac addreses are random, that is: there are no routability to them. To send a request to a mac address you'd need to scan the entire internet. 



# NPM 

Very shady because no need for any kind of authentication. Can run some scripts automatically by using some "preinstall" function


# 
ALG Application layer gateay
nat slipstreaming
arp spoofing attack
# 

Variational inference


Latent Varibles are hidden and cannot be observed. 
    . Intelligence 
    . Health
However, we can infer latent variables by exploiting the observed variables.
    . Raven's Progressive Matrices
    . Sat Scores
    . Blood Tests
    . Pressure

Considering latent variables Z and observed variables X. ]
We suppose that the latent variable causes the observed variable, that is: Z -> X.
    . In a bayesian treatment, we would imply that latent variables govern the distribution of the data. 
    . In particular, we would draw the latent variables from a prior density P(z) and relate them to the observations through the likelihood P( X|Z)


Our goal is to perform inference, that is. Estimate Some hIdden variable given some observation. 
    Infer Health given medical examinations
    Infer Inteligence given tests. 
More Formally, we want to infer
    P( Z|X) => P( Z , X) / P( X ) 
        . Why is this the case? WHat is the intuition of each of these terms? [[expand]]
        . How is this calculated? Isn't Z unobserved? [[expand]]

This is not always possible. P( X ) = Integral ( P(Z,X) * dZ)
    . Integrate over all the configurations of the latent variables, which has excponential cost in regards to the number of variables, becoming intractable very quickly. 


Variational Bayesian Methods

Since P( X ) is intractable, we can approximate the true posterior P( Z | X ) by using a variational distribution Q(Z) 
    . Also called guide. 
    . We use P to denote the true distribution and Q to denote the approximated distribution

Define a Family of distributions Q from with we are going to pick the ideal candidate, that better fits the true distribution P. 
We usually use a friendly distribution family, such as gaussians to simplify our life. 
Its Parameters are grouped in a vector Theta, so in practice we're looking for a Theta* that minimies the discrepance between Q* and P. 
Tehta and Z are often grouped toegher and called unobvserved variables. 
How to fide the best Q*?
    . Need a measure of similarity between p and q that we can use as a metric during our search
        .. We Use the Killabck-Leibler Divergence



The KL Div can be used to measure the smimilarity between tw distribitutions. 
    
    . Non Negative
    . Not Symetric. 
        .. Doesn't satisfy the triangle inequality
        .. KL( P || Q ) != KL( Q || P )
                            .. |> This one is called the backward
                |> This one is called the forward
            ... Trick: Use the bump of the P. 
    . Imagine a bi-modal distribution with two symmetric modes
        KL( P || Q ) is mode averaging
        KL( Q || P ) is mode fitting. 

How can we measure the similarity between KL( Q( Z ) , P(Z|X)) if we can't estimate P( Z | X ) in the first plance?


We can rewrite this equation such that 
    KL( Q( Z ) , P(Z|X)) = Eq[ log( q(z)) - log*p(x,z)] + log( p ( x ))
which means
    Eq[ log( p(x,z) ) -  log( q(z))  ] = log( p( x )) - KL( Q( Z ) , P(Z|X))

we can then just maximize the tractable quantity on the left.  This means we're maximizing log( p(x)) while minimizing KL( ... ). 

Since KL( ... ) is always positive, the quantity we're maximizing is a lower-bound for the log-evidence. We call this the Evidence Lower Bound. 
    
    ELBO( Q ) = Eq[ log( p( x, z)) - log( q(z))] = Eq[     log( p(x,z)  / q(z))   ]




Variational Inference focuses on optimization instead of integration, and can be applied to many probabilistic models. Is numerally stable and fast to converge.

            
        



https://mpatacchiola.github.io/blog/2021/01/25/intro-variational-inference.html
https://www.shakirm.com/papers/VITutorial.pdf

#

Statistical Inference
    Any mechanism by which we deduce the probabilities in our model based on data. 

    Inference links the observced data with our statiscal assumptions adn allows us to ask questions of our data: predicitions visualizatrion and model selection. 

![](2022-03-31-17-16-36.png)

![](2022-03-31-17-16-56.png)
Inference Methods

    Exat Methods
        . COnjugacy
        . Enumeration
    Numerical Integration
        . Qudrature
    Generalized method of moments
    
    Maximum Likelihood
    
    Maximum a posteriori

    Laplace Approximation

    Integrated nested laplace approximations

    Monte Carlo Methods

    Cavity Methods
    Variational Methods



#
Intercepting and decrypting https traffic with wireshar


SSLKEYLOGFILE environment variable is a path of textfile we can acces. 
Software that implements tls with typically write keys and others tls secrets to this file. This applies to curl chrome firefox and other desktop apps that use opensll libs. 

We can configure wireshark to read this file and decrypt the intercepted tls packets. 

https://www.trickster.dev/post/decrypting-your-own-https-traffic-with-wireshark/


#

Look Ma , no OS

Unikernels and their applications

Possibly the next step in the virtualization, after containers. 

Complexity comes into varities

    Necessary complexity
        Inherent because of the solving of hard problem 
    Unnecessary
        Lack of understanding of the problem
        Organic growth over time


Usual microservices architectures are very hard to debug
    . Very Hard to replicate the environment 1 to 1 
    
https://www.youtube.com/watch?v=W9F4pn9Lngc




Looking at the Application Stack

    Ocaml 
        Application Config
        Application

    Docker
        Language runtime
        Shared Libraries
        Docker RUntime

    Ubuntu
        Os User Processes
        OS Kernel
        Virtual HW Drivers

    HyperV
        Hypervisor
        Hardware Drivers
        Hardware

Largely Redundant
    Isolation provided by the docker runtime, by the user processes and the hypervisor. 
That is all to run a single ap, in a single user in a single server
This is unnecessarily complex

From the developers perspective, there are many black box layers beneath the running application. Layers that the developers are not interacting explicitly: As far as they're concerned , its turtles all the way down.

Overgeneralized systems
    By designed, posix is very generalized

A very large amount of complexity in the kernel regards the necessity to run concurrent users and applications. 
Needless permission checks - a legacy of the timesharing computers of the past.
Efficiency and duplication: Lots of storage and ram for things we're not using, such as floppy disk and tape drives; Unconfigured and unstarted services, and the wasted resources of unnecesary running services. 

This means we have a very large attack surface , in regards to security. 
 
How did we get here? 
    Natural eveolution
    Decades of backwards compatibility
    

Make it work -> Make it RIght -> Make it fast



What is a uni-kernel?
     

Unnecessarily complexity

        Service Metadata
            zookeeper
            consul
            etcd

        Memory Storage
            redis
            memcached
        
        Object storage
            swift stack
            s3
        RDBMS
            Postgres
            MariaDB
        Document DB
            COuchDB
            MongoDB

        COnfiguration Trget
            Ansible
            Puppet
            chef
        
        ORchestration
            Kubernetes
            Mesos
        Traffic Routing
            Nginx HAPROXYUU

# 


Decision Trees are desirable
    Scale well to larger datasets
    Robust against irrelevant features
    easy to visualize rationaliztion between predictions
    low bias, as there is minimal implicittly defined structure in the model, as opposed to linear regression, for example. 

    However, prone to high variance
    will overfit noisy data


Random forests inherit the benefit of a decision tree whils imporving upon the performance by reducing the variance. 
    . Train decision trees in subsets of the training data, as well as subsets of the feature space. 
    . REandomness reduces variance in the end meodel 
    

Since its non-parametrical, model behaviour varies significatnylu depending on which data was used for training. 
(Sampling can help with this)[https://www.jeremyjordan.me/content/images/2019/05/tree_ensemble.gif]. 
    . This is knwon as bootstrap aggregating or bagging for short. 

Since each tree sees only a subset of the data during training, we can get away without using a proper validation set. This is called "out of bag estimations"

https://www.jeremyjordan.me/random-forests/

#




# 
https://www.youtube.com/watch?v=qpC1YH0FhuY

